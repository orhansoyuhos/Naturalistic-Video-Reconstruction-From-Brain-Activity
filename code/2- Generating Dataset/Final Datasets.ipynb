{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### !!! IMPORTANT: The last 9 frames of all videos were cut before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Concatenate All RFsignals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3599, 216)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_t = 'training'\n",
    "sub_id = '18'\n",
    "roi = 'VIS'\n",
    "\n",
    "signals = []\n",
    "for run_i in range(1,9):\n",
    "    signals_run_i = np.transpose(np.load(f'{set_t}_signalsRF/sub-{sub_id}/{roi}/{run_i}_{set_t[:-3]}.npy'))\n",
    "    signals.append(signals_run_i)\n",
    "    \n",
    "all_training_RFsignals = np.concatenate(signals).astype('float32')\n",
    "\n",
    "np.save(f'{set_t}_signalsRF/sub-{sub_id}/{roi}/all_training_RFsignals', all_training_RFsignals)\n",
    "all_training_RFsignals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3599, 216)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_t = 'testing'\n",
    "sub_id = '18'\n",
    "roi = 'VIS'\n",
    "\n",
    "signals = []\n",
    "for run_i in range(1,9):\n",
    "    signals_run_i = np.transpose(np.load(f'{set_t}_signalsRF/sub-{sub_id}/{roi}/{run_i}_{set_t[:-3]}.npy'))\n",
    "    signals.append(signals_run_i)\n",
    "    \n",
    "all_testing_RFsignals = np.concatenate(signals).astype('float32')\n",
    "\n",
    "np.save(f'{set_t}_signalsRF/sub-{sub_id}/{roi}/all_testing_RFsignals', all_testing_RFsignals)\n",
    "all_testing_RFsignals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## = Case 1: \n",
    "Just Taking the Last Run as Test Set (ignoring similar* and overlapping frames**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([442, 432, 429, 479, 453, 430, 534, 328])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfFrames = [451, 441, 438, 488, 462, 439, 543, 337] \n",
    "numberOfFrames = np.array(numberOfFrames) - 9\n",
    "numberOfFrames\n",
    "\n",
    "# Except the last 2 runs, the final target frame numbers correspond to the number of fMRI volumes. \n",
    "# However, the targets and RFsignals have the equal number of row for each run at the end.\n",
    "# probably because of downsizing the videos accordingly 2s TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[442, 874, 1303, 1782, 2235, 2665, 3199, 3527]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxOfFrames = []\n",
    "record = 0\n",
    "\n",
    "for n in numberOfFrames:\n",
    "    idxOfFrames.append(n+record)\n",
    "    record += n \n",
    "\n",
    "idxOfFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3527, 96, 96, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_targets = np.load(f'training_videos/train_targets_warped.npy')\n",
    "training_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3199, 96, 96, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_training_targets = training_targets[:idxOfFrames[6],:,:,:]\n",
    "\n",
    "os.makedirs(f'Trials/sub-{sub_id}', exist_ok=True)\n",
    "os.makedirs(f'Trials/sub-{sub_id}/Case1', exist_ok=True)\n",
    "np.save(f'Trials/sub-{sub_id}/Case1/train_targets_case1.npy', np.array(final_training_targets))\n",
    "\n",
    "final_training_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3527, 96, 96, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_targets = np.load(f'testing_videos/test_targets_warped.npy')\n",
    "testing_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 96, 96, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_testing_targets = testing_targets[idxOfFrames[6]:idxOfFrames[7],:,:,:]\n",
    "\n",
    "os.makedirs(f'Trials/sub-{sub_id}', exist_ok=True)\n",
    "os.makedirs(f'Trials/sub-{sub_id}/Case1', exist_ok=True)\n",
    "np.save(f'Trials/sub-{sub_id}/Case1/test_targets_case1.npy', np.array(final_testing_targets))\n",
    "\n",
    "final_testing_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # RFsignals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_RFsignals(sub_id, set_t, roi, test_run, time_range=5, shift=4):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    time_range: how many frames you want as input in the time dimension.\n",
    "    shift: how many delays in frames.\n",
    "    test_run: select the run number for the test set\n",
    "    \n",
    "    '''\n",
    "    rel_dir = '/home/soyorh/Desktop/studyforrest/Preprocessing steps/'\n",
    "    \n",
    "    if set_t == 'training':\n",
    "        \n",
    "        number_of_run_files = len(glob(f'{rel_dir}{set_t}_videos/{set_t[:-3]}_video_run*'))\n",
    "        signals_list = []\n",
    "\n",
    "        for run_i in tqdm(range(1, number_of_run_files+1)):\n",
    "            \n",
    "            if run_i == test_run:\n",
    "                continue\n",
    "                \n",
    "            # leftOut_frames = shift + time_range  ('Cause fmri duration == movie duration) already done in target space\n",
    "            seen_img =  np.load(f'{rel_dir}{set_t}_videos/{set_t[:-3]}_video_run{run_i}.npy') #[:-leftOut_frames]\n",
    "            n_frames = seen_img.shape[0]\n",
    "            signal_selection = np.arange(time_range)[np.newaxis, :] + np.arange(shift, shift+n_frames)[:, np.newaxis]\n",
    "\n",
    "            # get_signals_from_run(sub_id, set_t, roi, run_i, signal_selection)\n",
    "            signals_run_i = np.transpose(np.load(f'{rel_dir}{set_t}_signalsRF/sub-{sub_id}/{roi}/{run_i}_{set_t[:-3]}.npy'))\n",
    "            signals_run_i = signals_run_i[signal_selection,  :]\n",
    "\n",
    "            signals_list.append(signals_run_i)\n",
    "\n",
    "            print(f'training_signals_{run_i}: {signals_run_i.shape}')\n",
    "\n",
    "        signals = np.concatenate(signals_list).astype('float32')\n",
    "        signals = signals[:, :, :, np.newaxis, np.newaxis].astype(np.float32)\n",
    " \n",
    "        print(f'training_signals.shape: {signals.shape}')\n",
    "    \n",
    "    elif set_t == 'testing':\n",
    "        \n",
    "        run_i = test_run\n",
    "                    \n",
    "        # leftOut_frames = shift + time_range  ('Cause fmri duration == movie duration) already done in target space\n",
    "        seen_img =  np.load(f'{rel_dir}{set_t}_videos/{set_t[:-3]}_video_run{run_i}.npy') #[:-leftOut_frames]\n",
    "        n_frames = seen_img.shape[0]\n",
    "        signal_selection = np.arange(time_range)[np.newaxis, :] + np.arange(shift, shift+n_frames)[:, np.newaxis]\n",
    "\n",
    "        # get_signals_from_run(sub_id, set_t, roi, run_i, signal_selection)\n",
    "        signals_run_i = np.transpose(np.load(f'{rel_dir}{set_t}_signalsRF/sub-{sub_id}/{roi}/{run_i}_{set_t[:-3]}.npy'))\n",
    "        signals_run_i = signals_run_i[signal_selection,  :]\n",
    "\n",
    "        print(f'testing_signals_{run_i}: {signals_run_i.shape}')\n",
    "\n",
    "        signals = signals_run_i.astype('float32')\n",
    "        signals = signals[:, :, :, np.newaxis, np.newaxis].astype(np.float32)\n",
    " \n",
    "        print(f'testing_signals.shape: {signals.shape}')\n",
    "\n",
    "    return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 159.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_signals_1: (442, 5, 216)\n",
      "training_signals_2: (432, 5, 216)\n",
      "training_signals_3: (429, 5, 216)\n",
      "training_signals_4: (479, 5, 216)\n",
      "training_signals_5: (453, 5, 216)\n",
      "training_signals_6: (430, 5, 216)\n",
      "training_signals_7: (534, 5, 216)\n",
      "training_signals.shape: (3199, 5, 216, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "set_t = 'training'\n",
    "sub_id = '18'\n",
    "roi = 'VIS'\n",
    "test_run = 8\n",
    "\n",
    "final_training_RFsignals = final_RFsignals(sub_id, set_t, roi, test_run, time_range=5, shift=4)\n",
    "\n",
    "np.save(f'Trials/sub-{sub_id}/Case1/train_RFsignals_case1.npy', np.array(final_training_RFsignals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_signals_8: (328, 5, 216)\n",
      "testing_signals.shape: (328, 5, 216, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "set_t = 'testing'\n",
    "sub_id = '18'\n",
    "roi = 'VIS'\n",
    "test_run = 8\n",
    "\n",
    "final_testing_RFsignals = final_RFsignals(sub_id, set_t, roi, test_run, time_range=5, shift=4)\n",
    "\n",
    "np.save(f'Trials/sub-{sub_id}/Case1/test_RFsignals_case1.npy', np.array(final_testing_RFsignals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## = Case 2: \n",
    "Dividing the test into the chunks of 160 (# In Total 22 chunks. The last one has 167 frames).\n",
    "Finding the chunk that has the minumum number of SSIM>=0.5.\n",
    "In our case it is the 6th chunk.\n",
    "\n",
    "6th chunk is the test set. The others are the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3527"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Total 22 chunks. The last one has 167 frames.\n",
    "Total = 21*160 + 167\n",
    "Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for i in range(22):\n",
    "    chunks.append(160)\n",
    "    \n",
    "chunks[21] = 167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[160,\n",
       " 320,\n",
       " 480,\n",
       " 640,\n",
       " 800,\n",
       " 960,\n",
       " 1120,\n",
       " 1280,\n",
       " 1440,\n",
       " 1600,\n",
       " 1760,\n",
       " 1920,\n",
       " 2080,\n",
       " 2240,\n",
       " 2400,\n",
       " 2560,\n",
       " 2720,\n",
       " 2880,\n",
       " 3040,\n",
       " 3200,\n",
       " 3360,\n",
       " 3527]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxOfChunks = []\n",
    "record = 0\n",
    "\n",
    "for n in chunks:\n",
    "    idxOfChunks.append(n+record)\n",
    "    record += n \n",
    "\n",
    "idxOfChunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3527, 96, 96, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_targets = np.load(f'training_videos/train_targets_warped.npy')\n",
    "training_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3367, 96, 96, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 6 # choose the test chunk to be excluded\n",
    "i_chunk = n - 1 \n",
    "\n",
    "before_chunk = training_targets[:idxOfChunks[i_chunk-1],:,:,:]\n",
    "after_chunk = training_targets[idxOfChunks[i_chunk]:Total,:,:,:]\n",
    "\n",
    "final_training_targets = np.concatenate([before_chunk, after_chunk])\n",
    "\n",
    "os.makedirs(f'Trials/sub-{sub_id}/Case2', exist_ok=True)\n",
    "np.save(f'Trials/sub-{sub_id}/Case2/train_targets_case2.npy', np.array(final_training_targets))\n",
    "\n",
    "final_training_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3527, 96, 96, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_targets = np.load(f'testing_videos/test_targets_warped.npy')\n",
    "testing_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 96, 96, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 6 # choose the test chunk\n",
    "i_chunk = n - 1 \n",
    "\n",
    "final_testing_targets = testing_targets[idxOfChunks[i_chunk-1]:idxOfChunks[i_chunk],:,:,:]\n",
    "\n",
    "os.makedirs(f'Trials/sub-{sub_id}/Case2', exist_ok=True)\n",
    "np.save(f'Trials/sub-{sub_id}/Case2/test_targets_case2.npy', np.array(final_testing_targets))\n",
    "\n",
    "final_testing_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # RFsignals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -> all_RFsignals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_RFsignals_case2(sub_id, set_t, roi, time_range=5, shift=4):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    time_range: how many frames you want as input in the time dimension.\n",
    "    shift: how many delays in frames.\n",
    "    test_run: select the run number for the test set\n",
    "    \n",
    "    '''\n",
    "    rel_dir = '/home/soyorh/Desktop/studyforrest/Preprocessing steps/'\n",
    "    \n",
    "    number_of_run_files = len(glob(f'{rel_dir}{set_t}_videos/{set_t[:-3]}_video_run*'))\n",
    "    signals_list = []\n",
    "\n",
    "    for run_i in tqdm(range(1, number_of_run_files+1)):\n",
    "\n",
    "        # leftOut_frames = shift + time_range  ('Cause fmri duration == movie duration) already done in target space\n",
    "        seen_img =  np.load(f'{rel_dir}{set_t}_videos/{set_t[:-3]}_video_run{run_i}.npy') #[:-leftOut_frames]\n",
    "        n_frames = seen_img.shape[0]\n",
    "        signal_selection = np.arange(time_range)[np.newaxis, :] + np.arange(shift, shift+n_frames)[:, np.newaxis]\n",
    "\n",
    "        # get_signals_from_run(sub_id, set_t, roi, run_i, signal_selection)\n",
    "        signals_run_i = np.transpose(np.load(f'{rel_dir}{set_t}_signalsRF/sub-{sub_id}/{roi}/{run_i}_{set_t[:-3]}.npy'))\n",
    "        signals_run_i = signals_run_i[signal_selection,  :]\n",
    "\n",
    "        signals_list.append(signals_run_i)\n",
    "\n",
    "        print(f'training_signals_run_i: {signals_run_i.shape}')\n",
    "\n",
    "    signals = np.concatenate(signals_list).astype('float32')\n",
    "    signals = signals[:, :, :, np.newaxis, np.newaxis].astype(np.float32)\n",
    "\n",
    "    print(f'training_signals.shape: {signals.shape}')\n",
    "\n",
    "    return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 140.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_signals_run_i: (442, 5, 216)\n",
      "training_signals_run_i: (432, 5, 216)\n",
      "training_signals_run_i: (429, 5, 216)\n",
      "training_signals_run_i: (479, 5, 216)\n",
      "training_signals_run_i: (453, 5, 216)\n",
      "training_signals_run_i: (430, 5, 216)\n",
      "training_signals_run_i: (534, 5, 216)\n",
      "training_signals_run_i: (328, 5, 216)\n",
      "training_signals.shape: (3527, 5, 216, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "set_t = 'training' # or 'testing': they are the same.\n",
    "sub_id = '18'\n",
    "roi = 'VIS'\n",
    "\n",
    "all_RFsignals = helper_RFsignals_case2(sub_id, set_t, roi, time_range=5, shift=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3527, 5, 216, 1, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_RFsignals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -> chunks_RFsignals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_RFsignals_chunks(sub_id, set_t, roi, test_chunk, chunks_RFsignals):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    time_range: how many frames you want as input in the time dimension.\n",
    "    shift: how many delays in frames.\n",
    "    test_chunk: select the chunk number for the test set\n",
    "    \n",
    "    '''   \n",
    "    \n",
    "    test_chunk -= 1\n",
    "    \n",
    "    if set_t == 'training':\n",
    "        \n",
    "        signals_list = []\n",
    "\n",
    "        for chunk_i in tqdm(range(len(chunks_RFsignals))):\n",
    "            \n",
    "            if chunk_i == test_chunk:\n",
    "                continue\n",
    "\n",
    "            chunk_RFsignal = chunks_RFsignals[chunk_i]\n",
    "            signals_list.append(chunk_RFsignal)\n",
    "\n",
    "            print(f'training_signals_{chunk_i+1}: {chunk_RFsignal.shape}')\n",
    "\n",
    "        signals = np.concatenate(signals_list)\n",
    " \n",
    "        print(f'training_signals.shape: {signals.shape}')\n",
    "    \n",
    "    elif set_t == 'testing':\n",
    "        \n",
    "        chunk_i = test_chunk\n",
    "        signals = chunks_RFsignals[chunk_i]\n",
    " \n",
    "        print(f'testing_signals_{chunk_i+1}: {signals.shape}')\n",
    "\n",
    "    return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_RFsignals = []\n",
    "N = 0\n",
    "    \n",
    "for i_chunk in range(len(idxOfChunks)):\n",
    "\n",
    "    chunk_RFsignal = all_RFsignals[N:idxOfChunks[i_chunk],:,:,:]\n",
    "    chunks_RFsignals.append(chunk_RFsignal)\n",
    "    \n",
    "    N = idxOfChunks[i_chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, (160, 5, 216, 1, 1), (167, 5, 216, 1, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_RFsignals), chunks_RFsignals[0].shape, chunks_RFsignals[21].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 25476.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_signals_1: (160, 5, 216, 1, 1)\n",
      "training_signals_2: (160, 5, 216, 1, 1)\n",
      "training_signals_3: (160, 5, 216, 1, 1)\n",
      "training_signals_4: (160, 5, 216, 1, 1)\n",
      "training_signals_5: (160, 5, 216, 1, 1)\n",
      "training_signals_7: (160, 5, 216, 1, 1)\n",
      "training_signals_8: (160, 5, 216, 1, 1)\n",
      "training_signals_9: (160, 5, 216, 1, 1)\n",
      "training_signals_10: (160, 5, 216, 1, 1)\n",
      "training_signals_11: (160, 5, 216, 1, 1)\n",
      "training_signals_12: (160, 5, 216, 1, 1)\n",
      "training_signals_13: (160, 5, 216, 1, 1)\n",
      "training_signals_14: (160, 5, 216, 1, 1)\n",
      "training_signals_15: (160, 5, 216, 1, 1)\n",
      "training_signals_16: (160, 5, 216, 1, 1)\n",
      "training_signals_17: (160, 5, 216, 1, 1)\n",
      "training_signals_18: (160, 5, 216, 1, 1)\n",
      "training_signals_19: (160, 5, 216, 1, 1)\n",
      "training_signals_20: (160, 5, 216, 1, 1)\n",
      "training_signals_21: (160, 5, 216, 1, 1)\n",
      "training_signals_22: (167, 5, 216, 1, 1)\n",
      "training_signals.shape: (3367, 5, 216, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "set_t = 'training'\n",
    "sub_id = '18'\n",
    "roi = 'VIS'\n",
    "test_chunk = 6\n",
    "\n",
    "final_training_RFsignals = final_RFsignals_chunks(sub_id, set_t, roi, test_chunk, chunks_RFsignals)\n",
    "\n",
    "np.save(f'Trials/sub-{sub_id}/Case2/train_RFsignals_case2.npy', np.array(final_training_RFsignals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_signals_6: (160, 5, 216, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "set_t = 'testing'\n",
    "sub_id = '18'\n",
    "roi = 'VIS'\n",
    "test_chunk = 6\n",
    "\n",
    "final_testing_RFsignals = final_RFsignals_chunks(sub_id, set_t, roi, test_chunk, chunks_RFsignals)\n",
    "\n",
    "np.save(f'Trials/sub-{sub_id}/Case2/test_RFsignals_case2.npy', np.array(final_testing_RFsignals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## = Case ?: \n",
    "type here the explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
